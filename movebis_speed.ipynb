{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "import folium\n",
    "import branca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min number of visits present for an entry to be taken into account\n",
    "MIN_VISITS = 10\n",
    "\n",
    "#use the data from the following year (2018, 2019 or 2020)\n",
    "DataYear = '2020'\n",
    "\n",
    "#municipality to be processed\n",
    "municipality = 'Leipzig'\n",
    "\n",
    "is_saxony = False\n",
    "\n",
    "#if we want to evaluate an area outside of Saxony we have to define our own rectangle\n",
    "if not is_saxony:\n",
    "    municipality = 'Hamburg'\n",
    "    poly_area = {'left': 9.9, 'top': 53.66, 'bottom': 53.46, 'right': 10.14} \n",
    "\n",
    "#use tight borders of the municipality or extend to the rectangle that contains the whole area\n",
    "include_surrounding = True\n",
    "\n",
    "#Should we reload original csv file? If false, prepared files from cache will be used if available.\n",
    "Load_Original_Data = False\n",
    "\n",
    "IsDebug = False\n",
    "\n",
    "#coordinate systems\n",
    "source_crs='EPSG:4326'\n",
    "target_crs='EPSG:3857'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-liver",
   "metadata": {},
   "source": [
    "# Load desired shape file\n",
    "This is done first in order to do the filtering for desired area as early as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "data_folder = \"data\\\\movebis\\\\\"\n",
    "data_filename = \"geschwindigkeiten_%s\" % DataYear\n",
    "data_fileext = \".csv.tar.gz\"\n",
    "cache_folder = \"cache\\\\\"\n",
    "cache_filename = cache_folder + data_filename + \"_%d_%s.csv\" % (MIN_VISITS, municipality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for shapes\n",
    "shapefile_folder = \"data\\\\shapefiles\\\\\"\n",
    "shapefile_filename = \"gem\" #Municipalities(='gem') or Counties(='kreis')\n",
    "shapefile_fileext = \".shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all shapes\n",
    "gem_sn = gpd.read_file(shapefile_folder + shapefile_filename + shapefile_fileext)\n",
    "#gem_sn = gem_sn.to_crs(target_crs)\n",
    "gem_sn = gem_sn.to_crs(source_crs)\n",
    "if IsDebug:\n",
    "    gem_sn.plot()\n",
    "    gem_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-safety",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if is_saxony:\n",
    "    #only use borders of our municipality\n",
    "    poly_municipality = gem_sn[gem_sn.ORTSNAME == municipality]\n",
    "\n",
    "    #calculate the rectangle containing the municipality\n",
    "    #to define a custom rectangle define the 4 sides with constants\n",
    "    if include_surrounding:\n",
    "        left = poly_municipality.total_bounds[0]\n",
    "        right = poly_municipality.total_bounds[2]\n",
    "        top = poly_municipality.total_bounds[3]\n",
    "        bottom = poly_municipality.total_bounds[1]\n",
    "        poly = Polygon([[left, bottom], [left, top], [right, top], [right, bottom], [left, bottom]])\n",
    "        poly_municipality = gpd.GeoDataFrame(gpd.GeoSeries(poly), columns=['geometry'], crs=source_crs)       \n",
    "else:\n",
    "    left = poly_area['left']\n",
    "    right = poly_area['right']\n",
    "    top = poly_area['top']\n",
    "    bottom = poly_area['bottom']\n",
    "    poly = Polygon([[left, bottom], [left, top], [right, top], [right, bottom], [left, bottom]])\n",
    "    poly_municipality = gpd.GeoDataFrame(gpd.GeoSeries(poly), columns=['geometry'], crs=source_crs)   \n",
    "    \n",
    "if IsDebug:\n",
    "    poly_municipality.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hybrid",
   "metadata": {},
   "source": [
    "#  read original data and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if cache file does not exist, we have to load original data\n",
    "if not os.path.isfile(cache_filename):\n",
    "    Load_Original_Data = True\n",
    "    \n",
    "if Load_Original_Data:\n",
    "    print('loading original data')    \n",
    "else:\n",
    "    print('using cache file ' + cache_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debugging: read the first 10 lines from the file\n",
    "#data_speed_test = pd.read_csv(data_folder + data_filename + data_fileext, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, nrows=10)\n",
    "#data_speed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read original data in chunks and write filtered to csv file into cache directory\n",
    "start = timeit.default_timer()\n",
    "        \n",
    "if (Load_Original_Data):\n",
    "    first = True #write header only on first loop\n",
    "    chunksize = 1000000\n",
    "    count = chunksize\n",
    "    if os.path.isfile(cache_filename):\n",
    "        os.remove(cache_filename)\n",
    "    for chunked_df in pd.read_csv(data_folder + data_filename + data_fileext, skip_blank_lines=True,\n",
    "                                       header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=chunksize):\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        #rename first column to 'geometry' (per default it has the name of the csv file)\n",
    "        chunked_df = chunked_df.rename(columns={chunked_df.columns[0]: \"geometry\"}) \n",
    "        \n",
    "        #keep only links with more than MIN_VISITS occurrences. We don't want backyards :-)\n",
    "        chunked_df = chunked_df[chunked_df.visits > MIN_VISITS].copy()\n",
    "       \n",
    "        #convert column with the coordinates into the right data type\n",
    "        chunked_df['geometry'] = chunked_df['geometry'].apply(wkt.loads)\n",
    "       \n",
    "        #convert to GeoDataFrame\n",
    "        chunked_gdf = gpd.GeoDataFrame(chunked_df, geometry='geometry', crs=source_crs)\n",
    "        #chunked_gdf = chunked_gdf.to_crs(target_crs)\n",
    "        \n",
    "        #Filter data to our municipality (this will take a while :-)) and save to cache file\n",
    "        chunked_gdf_municipality = gpd.clip(chunked_gdf, poly_municipality).copy()\n",
    "        \n",
    "        #gpd.clip() seems to be buggy: when the record contains identical latitude or longitude values, clip does\n",
    "        # not remove the record but leaves an empty geometry :-(.\n",
    "        #https://github.com/geopandas/geopandas/issues/1841\n",
    "        #Thus as a workaround we remove those records. (Issue #1)\n",
    "        chunked_gdf_municipality.drop(chunked_gdf_municipality[(chunked_gdf_municipality.geometry.is_empty)].index, inplace=True)\n",
    "        \n",
    "        chunked_gdf_municipality = chunked_gdf_municipality.to_crs(target_crs)\n",
    "        chunked_gdf_municipality.to_csv(cache_filename, index=True, header=first, mode='a')    \n",
    "        first = False    \n",
    "\n",
    "        end = timeit.default_timer()\n",
    "        print('%d %fsec' % (count, (end - start)))\n",
    "        count = count + chunksize        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read cached csv file\n",
    "gdf_municipality = pd.read_csv(cache_filename, skip_blank_lines=True) \n",
    "gdf_municipality['geometry'] = gdf_municipality['geometry'].apply(wkt.loads)\n",
    "gdf_municipality = gpd.GeoDataFrame(gdf_municipality, geometry=gdf_municipality['geometry'])\n",
    "gdf_municipality.crs = target_crs \n",
    "\n",
    "#some lines don't contain correct coordinates -> remove\n",
    "#This should no longer be neccessary after fixing issue #1 and rebuilding cached files\n",
    "gdf_municipality.drop(gdf_municipality[gdf_municipality.geometry.is_empty].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-technique",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "results_folder = \"results\\\\\"\n",
    "results_filename = results_folder + data_filename + \"_%d_%s\" % (MIN_VISITS, municipality)\n",
    "\n",
    "data_field = 'avg_speed_kmh'\n",
    "max_value = gdf_municipality[data_field].max()\n",
    "print(max_value)\n",
    "\n",
    "carto_attribution='\\u0026copy; \\u003ca href=\\\"http://www.openstreetmap.org/copyright\\\"\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\\"http://cartodb.com/attributions\\\"\\u003eCartoDB\\u003c/a\\u003e, CartoDB \\u003ca href =\\\"http://cartodb.com/attributions\\\"\\u003eattributions\\u003c/a\\u003e' # <-- note this\n",
    "custom_attribution=carto_attribution + ' | \\u0026copy; \\u003ca href=\\\"https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/33427A5A-0ADB-40B1-8A1A-390B67B0380B\"\\u003eMovebis\\u003c/a\\u003e'\n",
    "\n",
    "poly_municipality = poly_municipality.to_crs(target_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-evidence",
   "metadata": {},
   "source": [
    "## Display the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orange 238 127 0\n",
    "#blau   0 75 124\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cdict = {'red':   ((0.0, 238/255, 238/255), (1.0, 0.0, 0.0/255)),\n",
    "\n",
    "         'green': ((0.0, 127/255, 127/255), (1.0, 75/255, 75/255)),\n",
    "\n",
    "         'blue':  ((0.0, 0.0, 0.0), (1.0, 124/255, 124/255))\n",
    "        }\n",
    "plt.register_cmap(cmap=LinearSegmentedColormap('ADFCOrangeBlue', cdict))\n",
    "\n",
    "if IsDebug:\n",
    "    def plot_linearmap(cdict):\n",
    "        newcmp = LinearSegmentedColormap('testCmap', segmentdata=cdict, N=256)\n",
    "        rgba = newcmp(np.linspace(0, 1, 256))\n",
    "        fig, ax = plt.subplots(figsize=(4, 3), constrained_layout=True)\n",
    "        col = ['r', 'g', 'b']\n",
    "        for xx in [0.25, 0.5, 0.75]:\n",
    "            ax.axvline(xx, color='0.7', linestyle='--')\n",
    "        for i in range(3):\n",
    "            ax.plot(np.arange(256)/256, rgba[:, i], color=col[i])\n",
    "        ax.set_xlabel('index')\n",
    "        ax.set_ylabel('RGB')\n",
    "        plt.show()\n",
    "\n",
    "    plot_linearmap(cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-version",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for high res output: zoom 15, width 200, buffer 10\n",
    "#for preview: zoom 11, width 40, buffer 50\n",
    "#for debug: zoom 9, width 20, buffer 100\n",
    "\n",
    "zoom_level=11\n",
    "#dpi=zoom_level*20\n",
    "\n",
    "width=40\n",
    "height=width\n",
    "\n",
    "df_plot = gdf_municipality.copy()\n",
    "df_plot.geometry=df_plot.buffer(50)\n",
    "\n",
    "label_list=[\n",
    "    'bis 14',\n",
    "    #'12-14',\n",
    "    '14-17',\n",
    "    #'16-18',\n",
    "    '17-21',\n",
    "    #'20-22',\n",
    "    '21-24',\n",
    "    #'24-26',\n",
    "    'über 24']\n",
    "\n",
    "style_kwds = {'xtick.major.size': 3, 'ytick.major.size': 3,\n",
    "              'font.family':u'courier prime code', 'legend.frameon': True}\n",
    "\n",
    "print('creating plot')\n",
    "ax=df_plot.plot(column=data_field, scheme='userdefined', figsize=(width,height), legend=True, alpha=0.3, \n",
    "                cmap='YlOrRd', #cmap='ADFCOrangeBlue', linewidth=0.100,\n",
    "            classification_kwds={\n",
    "            # 'bins':[12,14,16,18,20,22,24,26]},\n",
    "                 'bins':[14,17,21,24]},\n",
    "            legend_kwds = { \n",
    "                #'numpoints':1,\n",
    "                'bbox_to_anchor':(1.0, 1.0),\n",
    "                'title': \"Durchschnttl. Geschwindigkeit pro Link\",\n",
    "                'prop': {'size': width / 2},\n",
    "                'title_fontsize': width / 2,\n",
    "                'markerscale': width / 20,\n",
    "                'labels':label_list\n",
    "                } #, style_kwds = style_kwds\n",
    "            )\n",
    "\n",
    "#adding municipality border layer\n",
    "print('adding map')\n",
    "if not include_surrounding:\n",
    "    edgecolor='black'\n",
    "else:\n",
    "    edgecolor='none'\n",
    "fin_plot=poly_municipality.plot(facecolor=\"none\", edgecolor=edgecolor, linewidths=0.6, figsize=(width,height), ax=ax)\n",
    "\n",
    "#adding basemap\n",
    "ctx.add_basemap(fin_plot, source=ctx.providers.CartoDB.Positron, zoom=zoom_level)\n",
    "#ctx.add_basemap(fin_plot, source=ctx.providers.Stamen.Terrain, zoom=zoom_level)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "#set background color. otherwise it would be transparent in PNG.\n",
    "fig.patch.set_facecolor(\"black\")\n",
    "\n",
    "#remove axis\n",
    "ax.set_axis_off()\n",
    "fin_plot.set_axis_off()\n",
    "\n",
    "#add title\n",
    "ax.set_title('Durchschnittliche Geschwindigkeit\\n Daten: Movebis - Projekt\\nJahr: %s Gemeinde: %s' % (DataYear, municipality), \\\n",
    "             size=width / 2, color=\"white\")\n",
    "\n",
    "#Quelle\n",
    "ax.text(0.995, 0.004, transform=ax.transAxes, horizontalalignment='right', size=width / 3,\\\n",
    "        s=\"Quelle: Movebis, https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/33427A5A-0ADB-40B1-8A1A-390B67B0380B\")\n",
    "\n",
    "fig.savefig(results_filename + ('_%d' % zoom_level) + '.png', bbox_inches='tight', pad_inches = 0)#, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-interstate",
   "metadata": {},
   "source": [
    "## HTML with zoomable map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf_municipality.copy()\n",
    "df[data_field]=df[data_field].round(0)\n",
    "\n",
    "#calculate center of map from poly_municipality\n",
    "location_lat = (poly_municipality.to_crs(source_crs)['geometry'].bounds.miny + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxy) / 2\n",
    "location_lon = (poly_municipality.to_crs(source_crs)['geometry'].bounds.minx + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxx) / 2\n",
    "\n",
    "#create map with tile source\n",
    "m = folium.Map(location=[location_lat, location_lon], \n",
    "               zoom_start=12, \n",
    "                tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png', \n",
    "                attr=custom_attribution)\n",
    "\n",
    "colorscale = branca.colormap.LinearColormap(['red','orange','yellow','green','green'], index=None, vmin=12, vmax=25, caption=data_field)\n",
    "\n",
    "def style_function(feature):\n",
    "    col=feature['properties'][data_field]\n",
    "    return {\n",
    "        'opacity': 0.8,\n",
    "        'weight': 3,\n",
    "        'color': 'grey' if col is None else colorscale(col)\n",
    "    }\n",
    "\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "         'weight': 8,\n",
    "        'color': 'grey'\n",
    "    }\n",
    "\n",
    "dummy=folium.GeoJson(\n",
    "    df,\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[data_field, 'visits']),\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function\n",
    ").add_to(m)\n",
    "\n",
    "#colorscale.caption = field\n",
    "m.add_child(colorscale)\n",
    "\n",
    "m.save(results_filename + '.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
