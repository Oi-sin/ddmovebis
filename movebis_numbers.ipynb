{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "import folium\n",
    "import branca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min number of visits present for an entry to be taken into account\n",
    "MIN_VISITS = 0\n",
    "\n",
    "#use the data from the following year (2018, 2019 or 2020)\n",
    "DataYear = '2020'\n",
    "\n",
    "#municipality to be processed\n",
    "municipality = 'Dresden'\n",
    "\n",
    "#Should we reload original csv file? If false, prepared files from cache will be used if available.\n",
    "Load_Original_Data = False\n",
    "\n",
    "IsDebug = False\n",
    "\n",
    "#coordinate systems\n",
    "source_crs='EPSG:4326'\n",
    "target_crs='EPSG:3857'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-arbor",
   "metadata": {},
   "source": [
    "# Load desired shape file\n",
    "This is done first in order to do the filtering for desired area as early as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "data_folder = \"data\\\\movebis\\\\\"\n",
    "data_filename = \"verkehrsmengen_%s\" % DataYear\n",
    "data_fileext = \".csv.tar.gz\"\n",
    "cache_folder = \"cache\\\\\"\n",
    "cache_filename = cache_folder + data_filename + \"_%d_%s.csv\" % (MIN_VISITS, municipality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for shapes\n",
    "shapefile_folder = \"data\\\\shapefiles\\\\\"\n",
    "shapefile_filename = \"gem\" #Municipalities(='gem') or Counties(='kreis')\n",
    "shapefile_fileext = \".shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all shapes\n",
    "gem_sn = gpd.read_file(shapefile_folder + shapefile_filename + shapefile_fileext)\n",
    "#gem_sn = gem_sn.to_crs(target_crs)\n",
    "gem_sn = gem_sn.to_crs(source_crs)\n",
    "if IsDebug:\n",
    "    gem_sn.plot()\n",
    "    gem_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use borders of our municipality\n",
    "poly_municipality = gem_sn[gem_sn.ORTSNAME == municipality]\n",
    "if IsDebug:\n",
    "    poly_municipality.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hybrid",
   "metadata": {},
   "source": [
    "#  read original data and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if cache file does not exist, we have to load original data\n",
    "if not os.path.isfile(cache_filename):\n",
    "    Load_Original_Data = True\n",
    "    \n",
    "if Load_Original_Data:\n",
    "    print('loading original data')    \n",
    "else:\n",
    "    print('using cache file ' + cache_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debugging: read the first 10 lines from the file\n",
    "#data_speed_test = pd.read_csv(data_folder + data_filename + data_fileext, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, nrows=10)\n",
    "#data_speed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-situation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read original data in chunks and write filtered to csv file into cache directory\n",
    "start = timeit.default_timer()\n",
    "\n",
    "if (Load_Original_Data):\n",
    "    first = True #write header only on first loop\n",
    "    count=0\n",
    "    chunksize=1000000\n",
    "    if os.path.isfile(cache_filename):\n",
    "        os.remove(cache_filename)\n",
    "    for chunked_df in pd.read_csv(data_folder + data_filename + data_fileext, skip_blank_lines=True,\n",
    "                                       header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=chunksize):\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        #rename first column to 'geometry' (per default it has the name of the csv file)\n",
    "        chunked_df = chunked_df.rename(columns={chunked_df.columns[0]: \"geometry\"}) \n",
    "        \n",
    "        #keep only links with more than MIN_VISITS occurrences. We don't want backyards :-)\n",
    "        chunked_df = chunked_df[chunked_df.occurrences > MIN_VISITS].copy()\n",
    "        \n",
    "        #convert column with the coordinates into the right data type\n",
    "        #bsp \"LINESTRING (13.8774464 51.0015535, 13.8774464 51.0016493)\",22.123343908730444,56\n",
    "        chunked_df['geometry'] = chunked_df['geometry'].apply(wkt.loads)\n",
    "       \n",
    "        #convert to GeoDataFrame\n",
    "        chunked_gdf = gpd.GeoDataFrame(chunked_df, geometry='geometry', crs=source_crs)\n",
    "        #chunked_gdf = chunked_gdf.to_crs(target_crs)\n",
    "\n",
    "        #Filter data to our municipality (this will take a while :-)) and save to cache file\n",
    "        chunked_gdf_municipality = gpd.clip(chunked_gdf, poly_municipality)\n",
    "        chunked_gdf_municipality = chunked_gdf_municipality.to_crs(target_crs)\n",
    "        chunked_gdf_municipality.to_csv(cache_filename, index=False, header=first, mode='a')    \n",
    "        first = False    \n",
    "\n",
    "        #some lines don't contain correct coordinates -> remove\n",
    "        chunked_df.drop(chunked_df[chunked_df.geometry == 'LINESTRING EMPTY'].index, inplace=True)\n",
    "\n",
    "        count=count+chunksize\n",
    "        end = timeit.default_timer()\n",
    "        print('%d %fsec' % (count, (end - start)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read cached csv file\n",
    "gdf_municipality = pd.read_csv(cache_filename, skip_blank_lines=True) \n",
    "gdf_municipality['geometry'] = gdf_municipality['geometry'].apply(wkt.loads)\n",
    "gdf_municipality = gpd.GeoDataFrame(gdf_municipality, geometry=gdf_municipality['geometry'])\n",
    "gdf_municipality.crs = target_crs    \n",
    "\n",
    "#some lines don't contain correct coordinates -> remove\n",
    "gdf_municipality.drop(gdf_municipality[gdf_municipality.geometry.is_empty].index, inplace=True)\n",
    "\n",
    "#print(type(gdf_municipality['geometry'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-technique",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "results_folder = \"results\\\\\"\n",
    "results_filename = results_folder + data_filename + \"_%d_%s\" % (MIN_VISITS, municipality)\n",
    "\n",
    "data_field = 'occurrences'\n",
    "max_value = gdf_municipality[data_field].max()\n",
    "print(max_value)\n",
    "\n",
    "carto_attribution='\\u0026copy; \\u003ca href=\\\"http://www.openstreetmap.org/copyright\\\"\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\\"http://cartodb.com/attributions\\\"\\u003eCartoDB\\u003c/a\\u003e, CartoDB \\u003ca href =\\\"http://cartodb.com/attributions\\\"\\u003eattributions\\u003c/a\\u003e' # <-- note this\n",
    "custom_attribution=carto_attribution + ' | \\u0026copy; \\u003ca href=\\\"https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/33427A5A-0ADB-40B1-8A1A-390B67B0380B\"\\u003eMovebis\\u003c/a\\u003e'\n",
    "\n",
    "poly_municipality = poly_municipality.to_crs(target_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-evidence",
   "metadata": {},
   "source": [
    "## Display the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-version",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_plot = gdf_municipality.copy()\n",
    "df_plot.geometry=df_plot.buffer(70)\n",
    "\n",
    "width=20\n",
    "height=width\n",
    "\n",
    "zoom_level=14\n",
    "dpi=zoom_level*20\n",
    "\n",
    "#TODO: werte basierend auf dem Maximum berechnen\n",
    "\n",
    "label_list=[\n",
    "    'bis 6',\n",
    "    '12-12',\n",
    "    '14-25',\n",
    "    '16-50',\n",
    "    '18-100',\n",
    "    '20-200',\n",
    "    'Ã¼ber 200']\n",
    "\n",
    "style_kwds = {'xtick.major.size': 3, 'ytick.major.size': 3,\n",
    "              'font.family':u'courier prime code', 'legend.frameon': True}\n",
    "\n",
    "print('creating plot')\n",
    "ax=df_plot.plot(column=data_field, scheme='userdefined', figsize=(width,height), legend=True, alpha=0.3, \n",
    "                cmap='rainbow',# linewidth=0.100,\n",
    "            classification_kwds={\n",
    "             'bins':[1,2,4,8,12,16,20]},\n",
    "            legend_kwds = { \n",
    "                #'numpoints':1,\n",
    "                'bbox_to_anchor':(1.0, 1.0),\n",
    "                'title': \"Anzahl pro Link\",\n",
    "                'labels':label_list } #, style_kwds = style_kwds\n",
    "            )\n",
    "\n",
    "print('adding map')\n",
    "#adding municipality border layer\n",
    "fin_plot=poly_municipality.plot(facecolor=\"none\", edgecolor='black', linewidths=0.6, figsize=(width,height), ax=ax)#, weight=1)\n",
    "\n",
    "#adding basemap\n",
    "ctx.add_basemap(fin_plot, source=ctx.providers.CartoDB.Positron, zoom=zoom_level)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "#remove axis\n",
    "ax.set_axis_off()\n",
    "fin_plot.set_axis_off()\n",
    "\n",
    "#add title\n",
    "ax.set_title('Anzahl erfasster Fahrten\\n Daten: Movebis - Projekt\\nJahr: %s Gemeinde: %s' % (DataYear, municipality))\n",
    "\n",
    "#Quelle\n",
    "ax.text(0.995, 0.004, transform=ax.transAxes, horizontalalignment='right', size='small',\\\n",
    "        s=\"Quelle: Movebis, https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/33427A5A-0ADB-40B1-8A1A-390B67B0380B\")\n",
    "\n",
    "fig.savefig(results_filename + ('_%d' % zoom_level) + '.png', bbox_inches='tight', pad_inches = 0, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-interstate",
   "metadata": {},
   "source": [
    "## HTML with zoomable map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf_municipality.copy()\n",
    "df[data_field]=df[data_field].round(0)\n",
    "\n",
    "#calculate center of map from poly_municipality\n",
    "location_lat = (poly_municipality.to_crs(source_crs)['geometry'].bounds.miny + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxy) / 2\n",
    "location_lon = (poly_municipality.to_crs(source_crs)['geometry'].bounds.minx + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxx) / 2\n",
    "\n",
    "#create map with tile source\n",
    "m = folium.Map(location=[location_lat, location_lon], \n",
    "               zoom_start=13, \n",
    "                tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png', \n",
    "                attr=custom_attribution)\n",
    "\n",
    "colorscale = branca.colormap.LinearColormap(['blue','orange','orange'], index=None, vmin=MIN_VISITS, vmax=max_value, caption=data_field)\n",
    "\n",
    "def style_function(feature):\n",
    "    col=feature['properties'][data_field]\n",
    "    return {\n",
    "        'opacity': 0.8,\n",
    "        'weight': 3,\n",
    "        'color': 'grey' if col is None else colorscale(col)\n",
    "    }\n",
    "\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "         'weight': 8,\n",
    "        'color': 'grey'\n",
    "    }\n",
    "\n",
    "dummy=folium.GeoJson(\n",
    "    df,\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[data_field]),\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function\n",
    ").add_to(m)\n",
    "\n",
    "#colorscale.caption = field\n",
    "m.add_child(colorscale)\n",
    "\n",
    "m.save(results_filename + '.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
