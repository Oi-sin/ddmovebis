{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "import folium\n",
    "import branca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min number of visits present for an entry to be taken into account\n",
    "MIN_VISITS = 10\n",
    "\n",
    "#use the data from the following year (2018, 2019 or 2020)\n",
    "DataYear = '2020'\n",
    "\n",
    "#municipality to be processed\n",
    "municipality = 'Dresden'\n",
    "\n",
    "#Should we reload original csv file? If false, prepared files from cache will be used if available.\n",
    "Load_Original_Data = False\n",
    "\n",
    "IsDebug = False\n",
    "\n",
    "#coordinate systems\n",
    "source_crs='EPSG:4326'\n",
    "target_crs='EPSG:3857'\n",
    "\n",
    "#TODO requests-cache einrichten\n",
    "#TODO Umland mit nehmen, also eine temp. rechteck basierend auf den Gemeindegrenzen zum filtern verwenden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-arbor",
   "metadata": {},
   "source": [
    "# Load desired shape file\n",
    "This is done first in order to do the filtering for desired area as early as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "data_folder = \"data\\\\movebis\\\\\"\n",
    "data_filename = \"verkehrsmengen_%s\" % DataYear\n",
    "data_fileext = \".csv.tar.gz\"\n",
    "cache_folder = \"cache\\\\\"\n",
    "cache_filename = cache_folder + data_filename + \"_%d_%s.csv\" % (MIN_VISITS, municipality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct filename for shapes\n",
    "shapefile_folder = \"data\\\\shapefiles\\\\\"\n",
    "shapefile_filename = \"gem\" #Municipalities(='gem') or Counties(='kreis')\n",
    "shapefile_fileext = \".shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all shapes\n",
    "gem_sn = gpd.read_file(shapefile_folder + shapefile_filename + shapefile_fileext)\n",
    "#gem_sn = gem_sn.to_crs(target_crs)\n",
    "gem_sn = gem_sn.to_crs(source_crs)\n",
    "if IsDebug:\n",
    "    gem_sn.plot()\n",
    "    gem_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use borders of our municipality\n",
    "poly_municipality = gem_sn[gem_sn.ORTSNAME == municipality]\n",
    "if IsDebug:\n",
    "    poly_municipality.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hybrid",
   "metadata": {},
   "source": [
    "#  read original data and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if cache file does not exist, we have to load original data\n",
    "if not os.path.isfile(cache_filename):\n",
    "    Load_Original_Data = True\n",
    "    \n",
    "if Load_Original_Data:\n",
    "    print('loading original data')    \n",
    "else:\n",
    "    print('using cache file ' + cache_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debugging: read the first 10 lines from the file\n",
    "#data_speed_test = pd.read_csv(data_folder + data_filename + data_fileext, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, nrows=10)\n",
    "#data_speed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-situation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read original data in chunks and write filtered to csv file into cache directory\n",
    "start = timeit.default_timer()\n",
    "\n",
    "if (Load_Original_Data):\n",
    "    first = True #write header only on first loop\n",
    "    count=0\n",
    "    chunksize=1000000\n",
    "    if os.path.isfile(cache_filename):\n",
    "        os.remove(cache_filename)\n",
    "    for chunked_df in pd.read_csv(data_folder + data_filename + data_fileext, skip_blank_lines=True,\n",
    "                                       header=0, sep=',', quotechar='\"', error_bad_lines=False, chunksize=chunksize):\n",
    "        \n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        #rename first column to 'geometry' (per default it has the name of the csv file)\n",
    "        chunked_df = chunked_df.rename(columns={chunked_df.columns[0]: \"geometry\"}) \n",
    "        \n",
    "        #keep only links with more than MIN_VISITS occurrences. We don't want backyards :-)\n",
    "        chunked_df = chunked_df[chunked_df.occurrences > MIN_VISITS].copy()\n",
    "        \n",
    "        #convert column with the coordinates into the right data type\n",
    "        #bsp \"LINESTRING (13.8774464 51.0015535, 13.8774464 51.0016493)\",22.123343908730444,56\n",
    "        chunked_df['geometry'] = chunked_df['geometry'].apply(wkt.loads)\n",
    "       \n",
    "        #convert to GeoDataFrame\n",
    "        chunked_gdf = gpd.GeoDataFrame(chunked_df, geometry='geometry', crs=source_crs)\n",
    "        #chunked_gdf = chunked_gdf.to_crs(target_crs)\n",
    "\n",
    "        #Filter data to our municipality (this will take a while :-)) and save to cache file\n",
    "        chunked_gdf_municipality = gpd.clip(chunked_gdf, poly_municipality)\n",
    "        chunked_gdf_municipality = chunked_gdf_municipality.to_crs(target_crs)\n",
    "        chunked_gdf_municipality.to_csv(cache_filename, index=False, header=first, mode='a')    \n",
    "        first = False    \n",
    "\n",
    "        #some lines don't contain correct coordinates -> remove\n",
    "        chunked_df.drop(chunked_df[chunked_df.geometry == 'LINESTRING EMPTY'].index, inplace=True)\n",
    "\n",
    "        count=count+chunksize\n",
    "        end = timeit.default_timer()\n",
    "        print('%d %fsec' % (count, (end - start)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read cached csv file\n",
    "\n",
    "#todo add warning if file not found\n",
    "\n",
    "gdf_municipality = pd.read_csv(cache_filename, skip_blank_lines=True) \n",
    "gdf_municipality['geometry'] = gdf_municipality['geometry'].apply(wkt.loads)\n",
    "gdf_municipality = gpd.GeoDataFrame(gdf_municipality, geometry=gdf_municipality['geometry'])\n",
    "gdf_municipality.crs = target_crs    \n",
    "\n",
    "#some lines don't contain correct coordinates -> remove\n",
    "gdf_municipality.drop(gdf_municipality[gdf_municipality.geometry.is_empty].index, inplace=True)\n",
    "\n",
    "#print(type(gdf_municipality['geometry'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-technique",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-schedule",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#construct filename for datafile based on desired parameters\n",
    "results_folder = \"results\\\\\"\n",
    "results_filename = results_folder + data_filename + \"_%d_%s\" % (MIN_VISITS, municipality)\n",
    "\n",
    "data_field = 'occurrences'\n",
    "max_value = gdf_municipality[data_field].max()\n",
    "\n",
    "carto_attribution='\\u0026copy; \\u003ca href=\\\"http://www.openstreetmap.org/copyright\\\"\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\\"http://cartodb.com/attributions\\\"\\u003eCartoDB\\u003c/a\\u003e, CartoDB \\u003ca href =\\\"http://cartodb.com/attributions\\\"\\u003eattributions\\u003c/a\\u003e' # <-- note this\n",
    "custom_attribution=carto_attribution + ' | \\u0026copy; \\u003ca href=\\\"https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/ECF9DF02-37DC-4268-B017-A7C2CF302006\"\\u003eMovebis\\u003c/a\\u003e'\n",
    "\n",
    "poly_municipality = poly_municipality.to_crs(target_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-evidence",
   "metadata": {},
   "source": [
    "## Display the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-version",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for high res output: zoom 15, width 200, buffer 10\n",
    "#for preview: zoom 11, width 40, buffer 70\n",
    "#for debug: zoom 9, width 20, buffer 100\n",
    "\n",
    "#parameters\n",
    "zoom_level=12\n",
    "\n",
    "width=100 #7*(2**((zoom_level-8)/2))\n",
    "height=width\n",
    "\n",
    "#dpi=50 #zoom_level*5\n",
    "#plt.figure(dpi=dpi)\n",
    "\n",
    "df_plot = gdf_municipality.copy()\n",
    "df_plot.geometry=df_plot.buffer(70) #line width in figure, smaller with larger zoom and width\n",
    "\n",
    "#calculate bins based on max value\n",
    "value_range = max_value - MIN_VISITS\n",
    "bins = [round(max_value*0.03), round(max_value*0.06), round(max_value*0.125),\n",
    "        round(max_value*0.25),round(max_value*0.50),round(max_value*0.75)]\n",
    "print(bins)\n",
    "print('max %d' % max_value)\n",
    "\n",
    "label_list=[\n",
    "    'bis %d' % bins[0] ,\n",
    "    '%d-%d' % (bins[0] + 1, bins[1]),\n",
    "    '%d-%d' % (bins[1] + 1, bins[2]),\n",
    "    '%d-%d' % (bins[2] + 1, bins[3]),\n",
    "    '%d-%d' % (bins[3] + 1, bins[4]),\n",
    "    '%d-%d' % (bins[4] + 1, bins[5]),\n",
    "    'über %d' % bins[5]]\n",
    "\n",
    "style_kwds = {'xtick.major.size': 3, 'ytick.major.size': 3,\n",
    "              'font.family':u'courier prime code', 'legend.frameon': True}\n",
    "\n",
    "print('creating plot')\n",
    "ax=df_plot.plot(column=data_field, scheme='userdefined', figsize=(width,height), legend=True, alpha=0.8, \n",
    "                cmap='YlOrRd', #'PiYG', #'rainbow', \n",
    "            classification_kwds={\n",
    "             'bins': bins},\n",
    "            legend_kwds = { \n",
    "                #'numpoints':1,\n",
    "                'bbox_to_anchor': (1.0, 1.0),\n",
    "                'title': \"Anzahl pro Link\",\n",
    "                'prop': {'size': width / 2},\n",
    "                'title_fontsize': width / 2,\n",
    "                'markerscale': width / 20,\n",
    "                'labels': label_list\n",
    "                } #, style_kwds = style_kwds\n",
    "            )\n",
    "ax.set_axis_bgcolor(\"white\")\n",
    "\n",
    "print('adding map')\n",
    "#adding municipality border layer\n",
    "fin_plot=poly_municipality.plot(facecolor=\"none\", edgecolor='black', linewidths=0.6, figsize=(width,height), ax=ax)#, weight=1)\n",
    "\n",
    "#adding basemap\n",
    "ctx.add_basemap(fin_plot, source=ctx.providers.CartoDB.Positron, zoom=zoom_level)\n",
    "#ctx.add_basemap(fin_plot, source=ctx.providers.OpenStreetMap.Mapnik, zoom=zoom_level)\n",
    "#ctx.add_basemap(fin_plot, source=ctx.providers.CartoDB.Voyager, zoom=zoom_level)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "#remove axis\n",
    "ax.set_axis_off()\n",
    "fin_plot.set_axis_off()\n",
    "\n",
    "#add title\n",
    "ax.set_title('Anzahl erfasster Fahrten\\n Daten: Movebis - Projekt\\nJahr: %s Gemeinde: %s' % (DataYear, municipality), size=width / 2)\n",
    "\n",
    "#Quelle\n",
    "ax.text(0.995, 0.004, transform=ax.transAxes, horizontalalignment='right', size=width / 3, \\\n",
    "        s=\"Quelle: Movebis, https://www.mcloud.de/web/guest/suche/-/results/suche/relevance/movebis/0/detail/ECF9DF02-37DC-4268-B017-A7C2CF302006\")\n",
    "\n",
    "fig.savefig(results_filename + ('_%d' % zoom_level) + '.png', bbox_inches='tight', pad_inches = 0)#, dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-wisdom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "buried-interstate",
   "metadata": {},
   "source": [
    "## HTML with zoomable map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gdf_municipality.copy()\n",
    "df[data_field]=df[data_field].round(0)\n",
    "\n",
    "#calculate center of map from poly_municipality\n",
    "location_lat = (poly_municipality.to_crs(source_crs)['geometry'].bounds.miny + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxy) / 2\n",
    "location_lon = (poly_municipality.to_crs(source_crs)['geometry'].bounds.minx + poly_municipality.to_crs(source_crs)['geometry'].bounds.maxx) / 2\n",
    "\n",
    "#create map with tile source\n",
    "m = folium.Map(location=[location_lat, location_lon], \n",
    "               zoom_start=13, \n",
    "                tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png', \n",
    "                attr=custom_attribution)\n",
    "\n",
    "colorscale = branca.colormap.LinearColormap(['blue','orange','orange'], index=None, vmin=MIN_VISITS, vmax=max_value, caption=data_field)\n",
    "\n",
    "def style_function(feature):\n",
    "    col=feature['properties'][data_field]\n",
    "    return {\n",
    "        'opacity': 0.8,\n",
    "        'weight': 3,\n",
    "        'color': 'grey' if col is None else colorscale(col)\n",
    "    }\n",
    "\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "         'weight': 8,\n",
    "        'color': 'grey'\n",
    "    }\n",
    "\n",
    "dummy=folium.GeoJson(\n",
    "    df,\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[data_field]),\n",
    "    style_function=style_function,\n",
    "    highlight_function=highlight_function\n",
    ").add_to(m)\n",
    "\n",
    "#colorscale.caption = field\n",
    "m.add_child(colorscale)\n",
    "\n",
    "m.save(results_filename + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-search",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
